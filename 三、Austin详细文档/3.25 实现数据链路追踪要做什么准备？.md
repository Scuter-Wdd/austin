**视频讲解：**
[![#24 全链路追踪基础（埋点）.mp4 (389.94MB)](https://gw.alipayobjects.com/mdn/prod_resou/afts/img/A*NNs6TKOR3isAAAAAAAAAAABkARQnAQ)]()从之前打印的日志以及能很快地排查出**接入层**的问题了，其实重头戏其实是在**处理层**上，回顾下处理层目前做的事情：
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649660567359-27a5f0a0-f7b4-4e0b-a46f-6e02e1fcb811.png#averageHue=%23f7f4f1&clientId=u9fb0af73-01e3-4&from=paste&id=ufeeac516&originHeight=942&originWidth=2582&originalType=url&ratio=1&rotation=0&showTitle=false&size=672991&status=done&style=none&taskId=u2bf3060f-6524-400b-bc38-87eb6064abb&title=)

在处理层上会有不少的**平台过滤规则**，这些过滤规则大多都不是针对于消息模板的，而是针对于userId(接收者)的。在这个处理过程中，记录下**每个消息模板中的每个用户的执行情况**就尤其重要了。

**1**、定位和排查问题。如果客户反馈用户收不到短信，一般情况下都在这个处理的过程中导致的（可能是被去重，可能是调用接口出问题）

**2**、对模板执行的整体链路数据分析。一个消息模板一天发送的量级，中途被**每个规则**过滤的量级，成功下发的量级以及消息最后被点击的量级。**除了点击数据，其他的数据都来源处理层**

基于上面的背景，我设计了一套埋点的规则，在处理**关键链路上**打上对应的点位📝
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649660628181-5993c728-0d0c-47ff-b3fe-f914573c162e.png#averageHue=%232d2d2d&clientId=u9fb0af73-01e3-4&from=paste&height=621&id=u33dbf0ba&originHeight=1242&originWidth=1790&originalType=binary&ratio=1&rotation=0&showTitle=false&size=271397&status=done&style=none&taskId=u5e006082-4cf1-431b-8c94-b72b791eec2&title=&width=895)
目前点位的信息还是不全的，随着系统的完善和接入各个渠道，这里的点位信息还会继续增加，只要我们认为有哪些地方是需要记录下来的，就可以增加。

可能看到这里你会觉得有些抽象，我请求一次接口打印下日志就容易懂啦：
```java
// 1、接入层打印日志（returnStr打印处理结果，而msg打印出入参信息）
2022-01-08 15:44:53.512 [http-nio-8080-exec-7] INFO  com.java3y.austin.utils.LogUtils - 
{"bizId":"1","bizType":"SendService#send","logId":"34df87fc-0489-46c1-b39f-cafd7652f55b",
"msg":"{\"code\":\"send\",\"messageParam\":{\"extra\":null,\"receiver\":\"13288888888\",\"variables\":{\"title\":\"yyyyyy\",\"contentValue\":\"66661641627893157\"}},\"messageTemplateId\":1}","operateDate":1641627893512,"returnStr":"{\"code\":\"00000\",\"msg\":\"操作成功\"}","success":true,"tag":"operation"}

// 2、处理层打印入口日志（表示成功消费到Kafka的消息 state=10）
2022-01-08 15:44:53.622 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  com.java3y.austin.utils.LogUtils - 
{"businessId":1000000120220108,"ids":["13288888888"],"state":10,"timestamp":1641627893622}

// 3、处理层打印入口日志（表示成功消费到Kafka的原始日志）
2022-01-08 15:44:53.622 [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] INFO  com.java3y.austin.utils.LogUtils - 
{"bizType":"Receiver#consumer","object":{"businessId":1000000120220108,"contentModel":{"content":"66661641627893157"},"deduplicationTime":1,"idType":30,"isNightShield":0,"messageTemplateId":1,"msgType":10,"receiver":["13288888888"],"sendAccount":66,"sendChannel":30,"templateType":10},"timestamp":1641627893622}

// 4、处理层打印逻辑过滤日志（state=20，表示这条消息由于配置了丢弃，已经丢弃掉）
2022-01-08 15:44:53.623 [pool-8-thread-3] INFO  com.java3y.austin.utils.LogUtils - 
{"businessId":1000000120220108,"ids":["13288888888"],"state":20,"timestamp":1641627893622}
```

我打印日志的核心逻辑是：

- 在**入口侧**（这里包括接口的入口以及刚消费Kafka的入口）需要打印出原始的信息。原始信息有了，才好对问题进行定位和排查，至少帮助我们复现
- 在处理过程中使用**某个标识**来标明处理的过程（10代表成功消费Kafka，20代表该消息已经被丢弃...)，并且**日志的格式是统一**的这样后续我们可以统一清洗该日志信息

![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649660566884-44facd84-b08f-4e8d-8c69-799801432926.png#averageHue=%23f8f3e4&clientId=u9fb0af73-01e3-4&from=paste&id=u0ab85762&originHeight=242&originWidth=1722&originalType=url&ratio=1&rotation=0&showTitle=false&size=123969&status=done&style=none&taskId=u8a0cb34a-28b5-4007-9796-11b3024f03e&title=)

至于打日志的过程就很简单了，只要抽取一个LogUtils类就好咯：
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649660567209-1b84b2bf-74a9-4539-ad67-6ce58a87c662.png#averageHue=%232c2c2b&clientId=u9fb0af73-01e3-4&from=paste&id=ud075fc79&originHeight=1190&originWidth=1080&originalType=url&ratio=1&rotation=0&showTitle=false&size=602667&status=done&style=none&taskId=u5a534247-5c1d-4ddb-8959-636091b2eab&title=)

那对于点击是怎么追踪的呢？其实也好办，在**下发的链接**上拼接businessId就好了。只要我们能拿到点击的数据，在链接上就可以判断是否存在track_code_bid字符，进而找到是哪个用户点击了哪个模板消息。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649660567360-34bb125d-e4e0-4fc3-8fa4-b2fe8838fa24.png#averageHue=%232e2c2b&clientId=u9fb0af73-01e3-4&from=paste&id=u2e3cc611&originHeight=1080&originWidth=1553&originalType=url&ratio=1&rotation=0&showTitle=false&size=688434&status=done&style=none&taskId=u4a1e3ef0-98c2-497e-98d2-d0120c74cb0&title=)
无论是打点日志还是原始日志，businessId会跟随着消息的生命周期始终。而businessId的构成只是通过**消息模板内容+时间**而成
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649660567696-fb3db96e-f4d6-49ee-af8a-95e3713346d1.png#averageHue=%23c0c3c3&clientId=u9fb0af73-01e3-4&from=paste&id=ua47e6116&originHeight=206&originWidth=1708&originalType=url&ratio=1&rotation=0&showTitle=false&size=80752&status=done&style=none&taskId=uc9981300-5c08-4f87-a39d-38a61a18721&title=)

现在已经打印出对应的数据链路信息了，但这是不够的，这只是将数据链路信息写到了服务器的本地上，还需要考虑以下的情况：

**1**、运行应用的服务器一般是集群，日志数据会记录到不同的机器上，排查和定位问题只能登录各个服务器查看

**2**、链路的数据需要**实时**，通过提供Web后台的界面功能快速让**业务方自助**查看整个流程

**3**、链路的数据需要离线保存用于对数据的分析以及留备份（本地日志往往存放不超过30天）

![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649660796646-dd88d831-12eb-4a1f-aa88-8033eff60ee4.png#averageHue=%23c7dbb0&clientId=u4793eb0a-f70e-4&from=paste&id=ude736ea9&originHeight=232&originWidth=2342&originalType=url&ratio=1&rotation=0&showTitle=false&size=149320&status=done&style=none&taskId=ue4b9f717-687d-4d82-9465-3584bc64ba4&title=)

这些在后面的文章都会有，代码都已经实现了，继续往下看吧

