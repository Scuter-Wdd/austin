
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649741914451-de5093fc-3298-4588-bf26-c60f0f5611d7.png#averageHue=%23faf8f5&clientId=ucf165e91-7f3c-4&from=paste&height=829&id=u9b267ac4&originHeight=1658&originWidth=3004&originalType=binary&ratio=1&rotation=0&showTitle=false&size=641706&status=done&style=none&taskId=uf84fe193-5a73-4c6d-bd01-bb25d19e51f&title=&width=1502)

这个模块主要是接入**流式处理平台**（flink），用于实时计算清洗数据给到业务以及系统维护者更方便去使用消息推送平台austin
## 01、为什么流式处理平台

我在老东家有过处理数据相关的经验，也看到过站内广告「效果数据」的发展历程。

所谓效果数据，说白了则是商家在平台上投放了广告，我们需要给商家看到广告带来的效果，最核心的是「曝光」「点击」「订单」，基于这几项数据再聚合些类roi的指标。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649741869929-ed6d2652-228f-4dfa-bbd0-90b2a5beeb91.png#averageHue=%23f5f5f5&clientId=ucf165e91-7f3c-4&from=paste&id=uac40becb&originHeight=448&originWidth=1172&originalType=url&ratio=1&rotation=0&showTitle=false&size=89040&status=done&style=none&taskId=ud33e72f1-bd75-4029-9aa3-72c46b48580&title=)

下面来聊聊这个「发展历程」，看完这个过程或许可以更好地了解**为什么**需要流式处理平台

**1**、PHP阶段：在最初时业务以及系统结构都比较简单，把「点击」和「订单」都存入数据库表，一把梭通过定时任务**全量**聚合，得到最终的效果数据，而「曝光」数据则是**次日**再写入效果数据表中。
在这个阶段里，由于数据量不大，通过定时任务全量来聚合数据也不是不可以，那时候商家都能接受该业务的延迟性

**2**、Java阶段：随着业务的发展，逐渐摒弃PHP化并且广告三层结构成型、数据量日益提升、站内中间件服务平台也发展起来。通过中间件团队提供的消费binlog框架，从架构上改变聚合模式，并这个阶段可以更快地给商家展示效果数据，大概**1min**出效果数据

**3**、流式处理平台阶段：流式处理平台是对「计算」或者说处理数据时的**抽象**，在这抽象基础上它更能充分利用系统的资源（一个大的任务被拆分多个小任务，然后分发到不同的机器上执行）

**4**、广告效果数据是先用的Storm作为流式处理平台，数据跑了几年都挺稳定的，性能吞吐量上也是满足业务使用的。后来Flink兴起，支持SQL、Exactly-Once、流批一体化等，随着公司内推广，我将广告效果数据从Strom改至Flink体系上，大概**秒级**出效果数据。（其实还可以压缩，但需要兼顾DB的性能成本，只要业务上能接受即可。**Trade-off**！）


在第三点我提出了「数据处理时的抽象」，我是这样理解的。在Storm里，定义spout为输入，bolt为中间处理或输出，而中间的数据流转为tuple，用shuffle机制来控制数据的流向
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649741870020-8cc67ff9-b070-4773-8e07-f700819bff27.png#averageHue=%23f9f9f9&clientId=ucf165e91-7f3c-4&from=paste&id=udcb4321f&originHeight=816&originWidth=1404&originalType=url&ratio=1&rotation=0&showTitle=false&size=382219&status=done&style=none&taskId=uf08625fb-5245-4a98-bd91-89513eb9d83&title=)

在Flink里，就有更加明确的**语义**来说明输入和输出了（程序的API也更有语义性）
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649741869879-3baad5fd-abe7-4792-a797-fa41ca9e1b7b.png#averageHue=%23faf9f9&clientId=ucf165e91-7f3c-4&from=paste&id=u4b8430ae&originHeight=354&originWidth=1224&originalType=url&ratio=1&rotation=0&showTitle=false&size=158149&status=done&style=none&taskId=ua97805fe-43dc-4bff-aeb0-c0c1ffa5d76&title=)

这些流处理平台都会数据处理进行了抽象，让我们更加方便且高效去处理数据，比如一般会以下的功能：
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649741869986-60ba621e-004f-4ec9-94d1-34b50224d520.png#averageHue=%23ebeaea&clientId=ucf165e91-7f3c-4&from=paste&id=u8c20f008&originHeight=558&originWidth=1476&originalType=url&ratio=1&rotation=0&showTitle=false&size=339213&status=done&style=none&taskId=uf41a3c6f-fd43-417e-b9ee-d5699b85cd0&title=)
## 02、AUSTIN哪里用到了流式处理平台

在前面austin系统已经设计了一部分的埋点信息了，在日志上都已经打印了下来。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649742014986-7e902a6d-6ac7-4e2b-bc24-4b3772220c69.png#averageHue=%232c2c2c&clientId=ucf165e91-7f3c-4&from=paste&height=778&id=u50e51afe&originHeight=1556&originWidth=1898&originalType=binary&ratio=1&rotation=0&showTitle=false&size=302351&status=done&style=none&taskId=u6019a71c-4fa5-4146-bc45-1b04caa35ad&title=&width=949)
但针对这一部分数据，迟迟没有做处理（不过之前有一起跟着学austin的小伙伴给我截了日志，我一眼就知道是哪里出了问题）

而接入流式处理平台就能对这一部分数据进行清洗（根据下发者维度、根据模板消息维度等等），得到清洗后的数据再给到接口去展示或者排查问题使用，能大大提高排查或者业务方的使用**效率**
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649741871047-7be60dba-8343-4ecb-a4dd-84c8c631cbe9.png#averageHue=%23fbfaf8&clientId=ucf165e91-7f3c-4&from=paste&id=u47e6e239&originHeight=680&originWidth=1960&originalType=url&ratio=1&rotation=0&showTitle=false&size=321051&status=done&style=none&taskId=u51054f6f-f473-4fba-9d3e-80c2653632a&title=)
## 03、FLINK入门

Flink从2018年开始流行，现在已经有很多的公司都在用Flink作为实时大数据处理的流式平台。至于我为什么会选择Flink的话，原因有以下：

**1**、我懂点儿Flink（主要是懒得学其他的了，目前还够用）

**2**、Flink发展了几年，成熟且被很多大公司用，社区活跃

**3**、Flink的官方文档挺不错的，适合学习和排查问题
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649741871189-8368636c-5214-475e-a946-bc6ea40f25e7.png#averageHue=%23f3efe9&clientId=ucf165e91-7f3c-4&from=paste&id=ubaf561b0&originHeight=602&originWidth=1868&originalType=url&ratio=1&rotation=0&showTitle=false&size=422654&status=done&style=none&taskId=uf81d00fc-f711-46f1-aaa6-a67875fb90f&title=)
首先我们安装下Flink，docker-compose.yml文件内容：
```yaml
version: "2.2"
services:
  jobmanager:
    image: flink:latest
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
      - SET_CONTAINER_TIMEZONE=true
      - CONTAINER_TIMEZONE=Asia/Shanghai
      - TZ=Asia/Shanghai
  taskmanager:
    image: flink:latest
    depends_on:
      - jobmanager
    command: taskmanager
    scale: 1
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 2
      - SET_CONTAINER_TIMEZONE=true
      - CONTAINER_TIMEZONE=Asia/Shanghai
      - TZ=Asia/Shanghai
```
完了之后直接docker-compose up -d就可以启动flink了，我们访问在浏览器输入ip:8081端口就能看到flink的后台了

![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649741871282-58f340e7-7d9e-4388-a3a8-8354f9961859.png#averageHue=%23fafafa&clientId=ucf165e91-7f3c-4&from=paste&id=ue52bd131&originHeight=1080&originWidth=2770&originalType=url&ratio=1&rotation=0&showTitle=false&size=351850&status=done&style=none&taskId=u1f781f0d-1fbd-4329-b5c7-1f2348cb2a4&title=)
简单看了下后台，就能知道我们在本地开发完打包成jar就可以在Submit New Job提交jar包给Flink去跑了
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649741871621-4f9af016-b99c-43c8-91f9-34325bcbae9d.png#averageHue=%23f8f8f8&clientId=ucf165e91-7f3c-4&from=paste&id=uca782a69&originHeight=1030&originWidth=3562&originalType=url&ratio=1&rotation=0&showTitle=false&size=653742&status=done&style=none&taskId=u25c337e4-2e7a-4364-8f44-97d8e657cbc&title=)
而在写代码的时候，可以参考官方文档给出的mvn命令去构建Flink的基础环境
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649741872464-44df5785-0d60-4f2d-86dc-011a1b3ca1ff.png#averageHue=%23f1d3c6&clientId=ucf165e91-7f3c-4&from=paste&id=ub0a85343&originHeight=1080&originWidth=1681&originalType=url&ratio=1&rotation=0&showTitle=false&size=611653&status=done&style=none&taskId=u49d77a7e-38da-4789-a18c-454dd1f4a49&title=)
当然啦，现在我已经搭好了，你们可以直接拉代码下来看austin-stream模块就完事了。如果你们是自己**从零搭**的话可能还要注意的是，pom里的plugin需要改动（不然打包会失败的），可参考我的pom文件
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649741872763-84c1ec5f-dce3-4349-b8e4-7d29ee20fda1.png#averageHue=%233b4145&clientId=ucf165e91-7f3c-4&from=paste&id=uc28d6982&originHeight=842&originWidth=870&originalType=url&ratio=1&rotation=0&showTitle=false&size=227295&status=done&style=none&taskId=ubbe9a89d-3f52-4a67-bfdb-1bc3d4d10f8&title=)
## 04、AUSTIN代码

从目前的代码结构和逻辑上看，还是非常简单的，没有学过Flink的同学应该都能看懂：
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649741873457-0bbdaba8-0d76-4090-8a9a-7255e43986be.png#averageHue=%232b2b2b&clientId=ucf165e91-7f3c-4&from=paste&id=u1f02f8ad&originHeight=1080&originWidth=2272&originalType=url&ratio=1&rotation=0&showTitle=false&size=854526&status=done&style=none&taskId=u506bb3cb-0207-4b43-a92b-f6d848fdcbf&title=)
目前主要实现了将**数据实时聚合**到Redis，分了两个维度：用户和消息模板（对应的Redis结构都已经写在了代码的注释上了）
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649741873968-80053e71-d4f5-47f7-8bd5-d5e2765dc959.png#averageHue=%232f2d2b&clientId=ucf165e91-7f3c-4&from=paste&id=u396e6022&originHeight=1080&originWidth=2202&originalType=url&ratio=1&rotation=0&showTitle=false&size=1232075&status=done&style=none&taskId=ud74344a0-f3ca-4ebb-9339-b37fd6e36c5&title=)
跟着做austin项目的小伙伴，只要在kafka创建对应的topic(我这里定义的topicName是austinLog)，并且在AustinFlinkConstant中填写Kafka的Broker信息以及Redis信息后，编译打包就完了。
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649741873680-1c33918e-fc90-4c93-b4eb-94a8c27e9e12.png#averageHue=%23302d2a&clientId=ucf165e91-7f3c-4&from=paste&id=u7de96f2a&originHeight=1158&originWidth=1080&originalType=url&ratio=1&rotation=0&showTitle=false&size=671648&status=done&style=none&taskId=u5a94619f-3dd1-48ec-8337-f3da67f9cca&title=)
提交到Flink平台之后就可以跑了：
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649741874101-79dc0cea-bf2d-49f4-8344-1183a0baf1ca.png#averageHue=%23f3f4eb&clientId=ucf165e91-7f3c-4&from=paste&id=ud27f6cf7&originHeight=1080&originWidth=2498&originalType=url&ratio=1&rotation=0&showTitle=false&size=485039&status=done&style=none&taskId=u2fd63cde-dd84-4d65-b501-32d5bb031c7&title=)
## 05、前端页面功能
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649742222628-0ad9d337-f148-4454-a79e-6c5c195ccb36.png#averageHue=%23ea5139&clientId=ucf165e91-7f3c-4&from=paste&height=411&id=u9e51ba2e&originHeight=822&originWidth=1752&originalType=binary&ratio=1&rotation=0&showTitle=false&size=92480&status=done&style=none&taskId=u8847c871-0eee-48bb-9e85-af96bcbe401&title=&width=876)

![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649742239157-627681d6-8c03-4477-b61d-1d08d28d348c.png#averageHue=%23fcfaf9&clientId=ucf165e91-7f3c-4&from=paste&height=608&id=ude3998fe&originHeight=1216&originWidth=3582&originalType=binary&ratio=1&rotation=0&showTitle=false&size=170856&status=done&style=none&taskId=u8144b4a6-2778-4bb0-9568-99fcccf7197&title=&width=1791)

今天就聊到这吧，对Flink感兴趣的同学可以看看我以往的几篇文章和官网入门下，我建议先可以把austin的代码先拉下来，部署一把自己体验体验，然后再看理论的知识。

**1**、[Flink入门](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&mid=2247494829&idx=1&sn=a10a38a57c760fa33322a2af2fc25c63&chksm=ebd4adacdca324ba7f860ae89ffdfd58b17d40806ed8ca6b820758e17e57ab8b7d4301424653&token=2053503009&lang=zh_CN#rd)
**2**、[Flink背压机制](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&mid=2247495581&idx=1&sn=f83ad7fe5d8c1d73d5d9153d3e89138d&chksm=ebd4ae9cdca3278a53b855ade2ed7fc510cddcb68d1e61893ece3d0094e81740de0c0278184d&token=2053503009&lang=zh_CN#rd)
**3**、[Flink CheckPoint机制](https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&mid=2247495992&idx=1&sn=2560f5c9d24e259f4955570acbd9cbe1&chksm=ebd4b039dca3392ffd6fc6a9121bded70d4982ea6abbb43c3f5e70d8cc1837521edbb6f80efc&token=2053503009&lang=zh_CN#rd)

