**视频讲解：**
[![#20 去重是如何实现的.mp4 (476.42MB)](https://gw.alipayobjects.com/mdn/prod_resou/afts/img/A*NNs6TKOR3isAAAAAAAAAAABkARQnAQ)]()austin支持两种去重的类型：**N分钟相同内容达到N次**去重和**一天内N次相同渠道频次**去重。

在最开始，我的第一版实现是这样的：
```java
public void duplication(TaskInfo taskInfo) {
    // 配置示例:{"contentDeduplication":{"num":1,"time":300},"frequencyDeduplication":{"num":5}}
    JSONObject property = JSON.parseObject(config.getProperty(DEDUPLICATION_RULE_KEY, AustinConstant.APOLLO_DEFAULT_VALUE_JSON_OBJECT));
JSONObject contentDeduplication = property.getJSONObject(CONTENT_DEDUPLICATION);
JSONObject frequencyDeduplication = property.getJSONObject(FREQUENCY_DEDUPLICATION);

// 文案去重
DeduplicationParam contentParams = DeduplicationParam.builder()
    .deduplicationTime(contentDeduplication.getLong(TIME))
    .countNum(contentDeduplication.getInteger(NUM)).taskInfo(taskInfo)
    .anchorState(AnchorState.CONTENT_DEDUPLICATION)
    .build();
contentDeduplicationService.deduplication(contentParams);


// 运营总规则去重(一天内用户收到最多同一个渠道的消息次数)
Long seconds = (DateUtil.endOfDay(new Date()).getTime() - DateUtil.current()) / 1000;
DeduplicationParam businessParams = DeduplicationParam.builder()
    .deduplicationTime(seconds)
    .countNum(frequencyDeduplication.getInteger(NUM)).taskInfo(taskInfo)
    .anchorState(AnchorState.RULE_DEDUPLICATION)
    .build();
frequencyDeduplicationService.deduplication(businessParams);
}
```
那时候很简单，**基本主体逻辑都写在这个入口上了**，应该都能看得懂。后来，群里滴滴哥表示这种代码不行，不能一眼看出来它干了什么。于是重构了一版，入口是这样的：
```java
public void duplication(TaskInfo taskInfo) {

    // 配置样例：{"contentDeduplication":{"num":1,"time":300},"frequencyDeduplication":{"num":5}}
    String deduplication = config.getProperty(DeduplicationConstants.DEDUPLICATION_RULE_KEY, AustinConstant.APOLLO_DEFAULT_VALUE_JSON_OBJECT);

//去重
DEDUPLICATION_LIST.forEach(
    key -> {
        DeduplicationParam deduplicationParam = builderFactory.select(key).build(deduplication, key);
        if (deduplicationParam != null) {
            deduplicationParam.setTaskInfo(taskInfo);
            DeduplicationService deduplicationService = findService(key + SERVICE);
            deduplicationService.deduplication(deduplicationParam);
        }
    }
);
}
```
他的思路就是把**构建去重参数**和**选择具体的去重服务**给封装起来了，在最外层的代码看起来就很简洁了。
后来，我基于上面的思路微改了下，代码最终演变成这样：
```java
public void duplication(TaskInfo taskInfo) {
    // 配置样例：{"deduplication_10":{"num":1,"time":300},"deduplication_20":{"num":5}}
    String deduplicationConfig = config.getProperty(DEDUPLICATION_RULE_KEY, CommonConstant.EMPTY_JSON_OBJECT);

// 去重
List<Integer> deduplicationList = DeduplicationType.getDeduplicationList();
for (Integer deduplicationType : deduplicationList) {
    DeduplicationParam deduplicationParam = deduplicationHolder.selectBuilder(deduplicationType).build(deduplicationConfig, taskInfo);
    if (Objects.nonNull(deduplicationParam)) {
        deduplicationHolder.selectService(deduplicationType).deduplication(deduplicationParam);
    }
}
}
```
到这，应该大多数人还能跟上吧？在讲具体的代码之前，我们先来简单看看去重功能的代码结构（这会对后面看代码有帮助）
![](https://cdn.nlark.com/yuque/0/2023/png/1285871/1678266541619-38c2f272-c649-4e4d-bf33-ad1ed0b6fe0d.png#averageHue=%233d4144&clientId=ue538a151-9cb6-4&from=paste&id=u9cad74a9&originHeight=404&originWidth=445&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u8713cd3d-d149-468c-b1a6-22bc1811a60&title=)

**注：**入口现已移到**com.java3y.austin.handler.action.DeduplicationAction#process**

去重的逻辑可以**统一抽象**为：在**X时间段**内达到了**Y阈值**，还记得我曾经说过：**「去重」的本质：「业务Key」+「存储」**。那么去重实现的步骤可以简单分为（**我这边存储就用的Redis**）：

- 通过Key从Redis获取记录
- 判断该Key在Redis的记录是否符合条件
- 符合条件的则去重，不符合条件的则重新塞进Redis更新记录

为了方便调整去重的参数，我把**X时间段**和**Y阈值**都**放到了配置里**{"deduplication_10":{"num":1,"time":300},"deduplication_20":{"num":5}}。目前有两种去重的具体实现：

1、5分钟内相同用户如果收到相同的内容，则应该被过滤掉
2、一天内相同的用户如果已经收到某渠道内容5次，则应该被过滤掉

从配置中心拿到配置信息了以后，Builder就是根据这两种类型去构建出DeduplicationParam。
Builder和DeduplicationService都用了类似的写法（**在子类初始化的时候指定类型，在父类统一接收，放到Map里管理**）
![](https://cdn.nlark.com/yuque/0/2023/png/1285871/1678266541611-4137ba11-c213-4432-ac3e-5505ab125999.png#averageHue=%23352c2b&clientId=ue538a151-9cb6-4&from=paste&id=u663793ce&originHeight=262&originWidth=1066&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=ub0f7ae9d-8735-4e38-86aa-dbe9e81eb95&title=)
![](https://cdn.nlark.com/yuque/0/2023/png/1285871/1678266541424-a61ec2c3-881f-4c62-9e48-3108f8960fd8.png#averageHue=%23342c2b&clientId=ue538a151-9cb6-4&from=paste&id=u14ed3dd5&originHeight=356&originWidth=1027&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u8dabe71f-80f8-4d92-bde1-fbcb70577b6&title=)
而统一管理这些服务，有个中心的地方，我把这取名为DeduplicationHolder
```java
/**
* @author huskey
* @date 2022/1/18
*/
@Service
public class DeduplicationHolder {

    private final Map<Integer, Builder> builderHolder = new HashMap<>(4);
    private final Map<Integer, DeduplicationService> serviceHolder = new HashMap<>(4);

    public Builder selectBuilder(Integer key) {
        return builderHolder.get(key);
    }

    public DeduplicationService selectService(Integer key) {
        return serviceHolder.get(key);
    }

    public void putBuilder(Integer key, Builder builder) {
        builderHolder.put(key, builder);
    }

    public void putService(Integer key, DeduplicationService service) {
        serviceHolder.put(key, service);
    }
}
```
前面提到的**业务Key**，是在AbstractDeduplicationService的子类下构建的：
![](https://cdn.nlark.com/yuque/0/2023/png/1285871/1678266541544-c8baf766-d641-43e4-b297-dc4e0740a2e3.png#averageHue=%232e2d2c&clientId=ue538a151-9cb6-4&from=paste&id=u1cf1d671&originHeight=773&originWidth=1150&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u38c7acbf-b02d-4712-a370-61c80b6964f&title=)
而具体的去重逻辑实现则都在LimitService下，**{一天内相同的用户如果已经收到某渠道内容5次}**是在SimpleLimitService中处理使用mget和pipelineSetEX就完成了实现。而**{5分钟内相同用户如果收到相同的内容}**是在SlideWindowLimitService中处理，使用了lua脚本完成了实现。
![](https://cdn.nlark.com/yuque/0/2023/png/1285871/1678266541515-5c9db970-5dc1-4a7f-a145-fc7010d16a77.png#averageHue=%232d2c2c&clientId=ue538a151-9cb6-4&from=paste&id=ue86f507a&originHeight=552&originWidth=1208&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=ueb5750ca-65d6-4843-853f-9ebfa8cf4de&title=)



LimitService的代码都来源于@[caolongxiu](https://gitee.com/caolongxiu)的pull request，**建议大家可以对比commit再学习一番**：[https://gitee.com/zhongfucheng/austin/pulls/19](https://gitee.com/zhongfucheng/austin/pulls/19)

> _1、频次去重采用普通的计数去重方法，限制的是每天发送的条数。_
> _2、内容去重采用的是新开发的基于redis中zset的滑动窗口去重，**可以做到严格控制单位时间内的频次**。3、redis使用lua脚本来保证原子性和减少网络io的损耗_
> _4、redis的key增加前缀做到数据隔离（后期可能有动态更换去重方法的需求）_
> _5、把具体限流去重方法从DeduplicationService抽取出来，DeduplicationService只需设置构造器注入时注入的AbstractLimitService（具体限流去重服务）类型即可动态更换去重的方法6、使用雪花算法生成zset的唯一value,score使用的是当前的时间戳_


针对滑动窗口去重，会引申出新的常见问题：

**Q：为什么要用滑动窗口？用redis的过期时间和这个相比两个的区别在哪里**
**A：**
![image.png](https://cdn.nlark.com/yuque/0/2024/png/1285871/1711013968786-12320774-6dbb-47bd-91f1-19b30c200ed7.png#averageHue=%23e6e6e6&clientId=uad48c685-7fc6-4&from=paste&height=673&id=u4da19b23&originHeight=673&originWidth=399&originalType=binary&ratio=1&rotation=0&showTitle=false&size=113507&status=done&style=none&taskId=u93bcb340-6c46-4523-8f7f-02c3ea3056c&title=&width=399)

**Q：limit.lua的逻辑？为什么要移除时间窗口的之前的数据？为什么ARGV[4]参数要唯一？为什么要expire？**
![](https://cdn.nlark.com/yuque/0/2022/png/1285871/1662301599423-05b3465c-6641-4afb-94ea-8e20796c96f9.png?x-oss-process=image%2Fresize%2Cw_715%2Climit_0#averageHue=%232e2e2e&from=url&id=h5tYE&originHeight=539&originWidth=715&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
**A：**使用**滑动窗口**可以保证N分钟达到N次进行去重。滑动窗口可以回顾下TCP的，也可以回顾下刷LeetCode时的一些算法题，那这为什么要移除，就不陌生了。
为什么ARGV[4]要唯一，具体可以看看zadd这条命令，我们只需要保证每次add进窗口内的成员是唯一的，那么就**不会触发有更新的操作**（我认为这样设计会更加简单些），而唯一Key用雪花算法比较方便。
为什么expire？，如果这个key只被调用一次。那就很有可能在redis内存常驻了，expire能避免这种情况。


