**视频介绍讲解**：
[![#17 SpringBoot接入Kafka.mp4 (896.4MB)](https://gw.alipayobjects.com/mdn/prod_resou/afts/img/A*NNs6TKOR3isAAAAAAAAAAABkARQnAQ)]()[![#18 使用线程池消费MQ.mp4 (324.44MB)](https://gw.alipayobjects.com/mdn/prod_resou/afts/img/A*NNs6TKOR3isAAAAAAAAAAABkARQnAQ)]()

在消费端首先看Receiver的代码，该类看起来看简单，就只有一个@KafkaListener注解修饰方法，从Kafka消费出来随后交给pending做处理
![image.png](https://cdn.nlark.com/yuque/0/2023/png/1285871/1689242941636-35623457-55b3-4f1f-a778-492e9f129394.png#averageHue=%232c2c2b&clientId=uc0c58353-e59f-4&from=paste&height=587&id=u6794926c&originHeight=587&originWidth=1230&originalType=binary&ratio=1&rotation=0&showTitle=false&size=91038&status=done&style=none&taskId=u0a876768-8d3c-4607-b202-fa864627001&title=&width=1230)
我用的是@KafkaListener注解从Kafka拉取消息，而没有用低级的Kafka api，原因无他：**在项目前期无需做到完美，等有瓶颈的时候再想办法就好了**。虽说如此，但我写的时候还是给我带来了不少的麻烦。

**第一个问题**：@KafkaListener是一个注解，从源码注释看它的传值只能够用Spring EL表达式和读取某个配置。但要知道的是，我的目的是想有**多个group消费同一个topic**。而我不可能说给每个group都定义一个消费的方法吧？（**写这种破代码，我都睡不着觉**）

翻了一个晚上技术博客我都没找到方案，甚至还发了个朋友圈吐槽下有没有人遇到过。第二天我仔细翻了下Spring的官方文档，终于给我找到了方案。
![](https://cdn.nlark.com/yuque/0/2022/jpeg/1285871/1649407821528-cf9e3009-d6eb-4ce2-b69f-8ba0075cecaf.jpeg#averageHue=%23f1efee&clientId=u24abb455-1b4a-4&from=paste&id=u35aa90b9&originHeight=1080&originWidth=2125&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=ue951a9f8-29b1-4ab3-a55f-65824e654f5&title=)
[https://docs.spring.io/spring-kafka/reference/kafka/receiving-messages/kafkalistener-attrs.html](https://docs.spring.io/spring-kafka/reference/kafka/receiving-messages/kafkalistener-attrs.html)

**还是官方文档实在**！

有了解决办法了以后，那事情就好办了。既然我是每种消息渠道的每种消息类型都要隔离，那我把这给枚举出来就完事啦！
![](https://cdn.nlark.com/yuque/0/2022/jpeg/1285871/1649407821551-a5f427a0-359d-4e2f-b46c-760c7381595b.jpeg#averageHue=%232c2c2b&clientId=u24abb455-1b4a-4&from=paste&id=uf40f0aa7&originHeight=806&originWidth=2080&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=uaefd110a-f2a8-4c83-861d-a91be103e7c&title=)

我的**Receiver**是多例的，那么只要我遍历这个List就好了（初始化消费者在**ReceiverStart**类上）

![](https://cdn.nlark.com/yuque/0/2022/jpeg/1285871/1649407821538-1e247852-8b31-440f-810a-ba75388e4356.jpeg#averageHue=%232e2c2b&clientId=u24abb455-1b4a-4&from=paste&id=ub15e1dc6&originHeight=1080&originWidth=1582&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u028d702d-36c8-400c-aa0d-25f45aabf0f&title=)
ReceiverStart的init方法会初始化Receiver消费者（有多少个groupId就会初始化多少个消费者）。而groupIdEnhancer实际上就是**每一个**Receiver初始化的时候做了**动态的切面，**拿到对应的**@KafkaListener注解**，修改其groupId。

解决问题就是：我们的消费者逻辑是一样的，但需要有多个独立的消费者，**通过切面这种方式能让我们不用手动地创建，然后手动指定groupId**。

解决了用@KafkaListener注解动态传入groupId 进而创建多个消费者了之后。

**我又遇到了第二个问题**：Spring有@Aysnc注解来**优雅**实现线程池的方法调用。我之前是没用过@Aysnc注解的，但我看了下原理和使用姿势。我感觉这样挺优雅的（**优雅永不过时**）。

但是用@Aysnc是肯定要**自己创建线程池**，并且我要给每个消费者都创建自己**独有**的线程池。而我不可能说给每个group都定义一个创建线程池的方法吧？（**写这种破代码，我都睡不着觉**）

这次翻了官网和各种技术博客，都没能解决掉我的问题：**在Spring环境下@Async**注解上动态传入线程池实例，以及创建线程池实例时可支持根据条件传参。

最后只能放弃掉@Aysnc注解了，以编程的方式去实现：
![](https://cdn.nlark.com/yuque/0/2022/jpeg/1285871/1649407821523-9f1eefed-02c5-4bff-94e8-395e24153383.jpeg#averageHue=%232e2c2b&clientId=u24abb455-1b4a-4&from=paste&id=uad0b7219&originHeight=1080&originWidth=1768&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u5e0a4404-5989-4d36-b0b3-8eb0ae2855b&title=)
下面是TaskPendingHolder的实现（无非就是给每个消费者创建对应的线程池），目前已经做成是**动态线程池**了**《第三章 如何优雅调整线程池参数》**？：
![image.png](https://cdn.nlark.com/yuque/0/2022/png/1285871/1649407987293-efb8a2d1-4c81-4ebe-a93f-0d76617a9fab.png#averageHue=%232d2b2b&clientId=u24abb455-1b4a-4&from=paste&height=799&id=u3c976e33&originHeight=799&originWidth=1016&originalType=binary&ratio=1&rotation=0&showTitle=false&size=109862&status=done&style=none&taskId=u5faec919-8bd8-4bb0-837a-07ba3808eda&title=&width=1016)
而Task实现又是一个责任链，本来是把操作都列举出来，后来想可能后面还会增加，那就会不断膨胀，于是就改造成责任链了。责任链配置类：**com.java3y.austin.handler.config.TaskPipelineConfig**
![image.png](https://cdn.nlark.com/yuque/0/2023/png/1285871/1692588132687-7e3d7036-1531-4d95-8ae9-b3f33b93a6d5.png#averageHue=%236a8568&clientId=u9aec5cdb-5276-4&from=paste&height=817&id=u7aa70c63&originHeight=817&originWidth=1853&originalType=binary&ratio=1&rotation=0&showTitle=false&size=203552&status=done&style=none&taskId=uc007e9f0-8920-4889-bf90-75302b0c549&title=&width=1853)
由于**资源共用，**股东们是能直接用我的远程服务的：Kafka的Topic是共享的，Group消费者也是共享的，在不修改的前提下，直接使用会带来一个问题。

当同时有两个或以上的股东在本地启动了Austin，那就会争抢消费这个Topic（相当于一个消费者组里起了多个消费者），导致在测试下发的时候可能收不到自己调试的消息（被别的股东抢去了）。

要解决这个问题我第一时间的想法很简单：不同的股东使用不同的group（**相当于每个股东都会有独立的消费者组**），那不就完事了嘛？正好我的groupId生成是依赖渠道的code，改掉code就完事咯。
![](https://cdn.nlark.com/yuque/0/2022/png/1285871/1657199404992-3046c58a-0748-49c9-8412-858509d1405a.png#averageHue=%23565b3f&from=url&id=Z2sIM&originHeight=1680&originWidth=3452&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
但这还是有问题的：每个股东有独立的消费者组，意味着每个股东能消费整个topic的所有消息，这又意味着股东会接受到其他股东的测试消息（明明只想要自己测试的消息，却来了一条其他人发的）。

要解决这个问题，除了给每个股东一个独立的topic，那就是**根据tag过滤**啦。

在Kafka实现这种效果，挺简单的：**在发送的时候，把tag写进Kafka的头部，在消费前把非自身tag的消息过滤掉就完事了**。
![](https://cdn.nlark.com/yuque/0/2022/png/1285871/1659535257836-e53bce97-8e43-461d-995a-95b5fdf5b7ae.png#averageHue=%232f2c2b&clientId=u67d636d1-4829-4&from=paste&id=ud6824fbb&originHeight=553&originWidth=1224&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=ubd3eb9eb-ee61-47db-a5d1-4d59d0fbc0e&title=)
![](https://cdn.nlark.com/yuque/0/2022/png/1285871/1659535257852-4735ce88-ae8d-4a07-904c-8629557e3426.png#averageHue=%232c2c2b&clientId=u67d636d1-4829-4&from=paste&id=u7face91e&originHeight=680&originWidth=1485&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=uc879af8e-51fd-458e-bdcb-31680703e99&title=)

